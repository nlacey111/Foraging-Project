{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb8734e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import foraging_envs\n",
    "from torch import nn\n",
    "from convert_net import *\n",
    "from stable_baselines3 import DQN\n",
    "import os\n",
    "\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import plot_results,  ts2xy\n",
    "\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af534be",
   "metadata": {},
   "source": [
    "Create a folder structure for saving this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a main folder for the new saved model and associated monitor files\n",
    "folder_main = \"Saved Models/DQN_foraging_06_03_2024\"\n",
    "# folder_save = f\"{folder_main}/dqn_save\"\n",
    "\n",
    "os.makedirs(folder_main, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a3fd3",
   "metadata": {},
   "source": [
    "Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0215fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"foraging_envs/foraging-two\", episode_length = 100, flower_distribution = \"uniform\", decay_parameter = .25, travel_time = 2, render_mode = \"human\")\n",
    "env = Monitor(env, folder_main)\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b40c70",
   "metadata": {},
   "source": [
    "Train the model, all monitor functions save here as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9e85d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -15.9    |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1841     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 400      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 74       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | -2.53    |\n",
      "|    exploration_rate | 0.367    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1574     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 800      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 174      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=1000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.209    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 1000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0652   |\n",
      "|    n_updates        | 224      |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 2.55     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1327     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0392   |\n",
      "|    n_updates        | 274      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 3.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1270     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 1600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 374      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 2000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 474      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 4.61     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1160     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 5.25     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1137     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00682  |\n",
      "|    n_updates        | 574      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 6.13     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 1135     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 2800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00379  |\n",
      "|    n_updates        | 674      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 3000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00289  |\n",
      "|    n_updates        | 724      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 6.37     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 1092     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00265  |\n",
      "|    n_updates        | 774      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 6.69     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 1102     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000588 |\n",
      "|    n_updates        | 874      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 4000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000427 |\n",
      "|    n_updates        | 974      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 6.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 1068     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 4000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 6.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 1070     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 4400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000594 |\n",
      "|    n_updates        | 1074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.08     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 1074     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 4800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000178 |\n",
      "|    n_updates        | 1174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000198 |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.16     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 1048     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 5200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00217  |\n",
      "|    n_updates        | 1274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.28     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 1056     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 5600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000231 |\n",
      "|    n_updates        | 1374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 6000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000169 |\n",
      "|    n_updates        | 1474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.37     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 1037     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 6000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.45     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 1034     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 6400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000217 |\n",
      "|    n_updates        | 1574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.44     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 1034     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 6800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.8e-05  |\n",
      "|    n_updates        | 1674     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 7000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000422 |\n",
      "|    n_updates        | 1724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.52     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 1033     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 7200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0056   |\n",
      "|    n_updates        | 1774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.57     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 1045     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 7600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.4e-05  |\n",
      "|    n_updates        | 1874     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 8000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.31e-05 |\n",
      "|    n_updates        | 1974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.62     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 1041     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 8000     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.73     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 1051     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 8400     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000228 |\n",
      "|    n_updates        | 2074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.74     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 1055     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 8800     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000347 |\n",
      "|    n_updates        | 2174     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 9000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0005   |\n",
      "|    n_updates        | 2224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.64     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 1048     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 9200     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000274 |\n",
      "|    n_updates        | 2274     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.7      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 1061     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 9600     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000137 |\n",
      "|    n_updates        | 2374     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000135 |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 7.7      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 1051     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 10000    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 8.65     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 1059     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 10400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 2574     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 8.51     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 1066     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 2674     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=11000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 11000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00166  |\n",
      "|    n_updates        | 2724     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 8.46     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 1056     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 11200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 2774     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 8.47     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 1058     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 11600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.96e-05 |\n",
      "|    n_updates        | 2874     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=3.52 +/- 0.00\n",
      "Episode length: 100.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 100      |\n",
      "|    mean_reward      | 3.52     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 12000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00909  |\n",
      "|    n_updates        | 2974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 100      |\n",
      "|    ep_rew_mean      | 8.56     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 1049     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 12000    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x26fd9fdad50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make network- i will need these parameters for the copycat network\n",
    "net_arch = [64, 64]\n",
    "activation_fn = nn.ReLU\n",
    "policy_kwargs = dict(net_arch = net_arch, activation_fn = activation_fn)\n",
    "\n",
    "# create DQN model \n",
    "callback = EvalCallback(env, best_model_save_path=folder_main, log_path=folder_main, eval_freq=1000, deterministic=True, n_eval_episodes=5)\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1, policy_kwargs = policy_kwargs)\n",
    "# train the model\n",
    "model.learn(total_timesteps=12000, progress_bar=False, log_interval=4, callback = callback)\n",
    "\n",
    "# ignoring network_copy until i can put it in the saved folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a85260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv at 0x26fda090c30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c72cd9",
   "metadata": {},
   "source": [
    "I believe that the monitor where best model is saved has the network information that i need. So it may not be necessary to save the model separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc80b481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from  stable_baselines3.common import results_plotter\n",
    "\n",
    "results_plotter.plot_results(\n",
    "    [folder_main], 10000, results_plotter.X_TIMESTEPS, \"DQN Foraging Environment Training Results\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e27e0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "model = DQN.load(f\"{folder_main}/best_model.zip\", env=env, policy_kwargs=policy_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd800722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.get_env())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4242724",
   "metadata": {},
   "source": [
    "Make a function to create network copy- see if it's possible to save this to the best_model.zip folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3beb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'reset'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m activation_fn = model.policy.activation_fn\n\u001b[32m      6\u001b[39m env = model.get_env\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m state, info = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m()\n\u001b[32m      8\u001b[39m n_observations = \u001b[38;5;28mlen\u001b[39m(state)\n\u001b[32m     10\u001b[39m network_copy_args = \u001b[38;5;28mdict\u001b[39m(obs_space = n_observations, action_space =env.action_space.n, net_arch = net_arch, activation_fn = activation_fn)\n",
      "\u001b[31mAttributeError\u001b[39m: 'function' object has no attribute 'reset'"
     ]
    }
   ],
   "source": [
    "# find net_arch and activation_fn from the model \n",
    "net_arch = model.policy.net_arch\n",
    "activation_fn = model.policy.activation_fn\n",
    "\n",
    "\n",
    "env = model.get_env(\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "network_copy_args = dict(obs_space = n_observations, action_space =env.action_space.n, net_arch = net_arch, activation_fn = activation_fn)\n",
    "network_copy = CustomNetwork(network_copy_args)\n",
    "network_copy = copy_weights(from_net=model, to_net = network_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fabefa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQNPolicy\n"
     ]
    }
   ],
   "source": [
    "# print out DQN\n",
    "print(model.policy._get_name())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
